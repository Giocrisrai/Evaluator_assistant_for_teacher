# .env.example - Copia este archivo a .env y configura tus tokens

# =====================================
# CONFIGURACIÓN OBLIGATORIA
# =====================================

# GitHub Personal Access Token (OBLIGATORIO)
# Obtener en: https://github.com/settings/tokens
# Permisos necesarios: repo, read:user
GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# =====================================
# CONFIGURACIÓN DE LLM (ELEGIR UNO)
# =====================================

# Proveedor de IA a usar: github, gemini, huggingface, ollama
LLM_PROVIDER=github

# API Key según el proveedor elegido
LLM_API_KEY=tu_api_key_aqui

# =====================================
# PROVEEDORES ESPECÍFICOS
# =====================================

# 1. GITHUB MODELS (Recomendado - GRATIS)
# Registro: https://github.com/marketplace/models
# Modelos disponibles: gpt-4o-mini, gpt-3.5-turbo, Meta-Llama-3.1-8B-Instruct
# GITHUB_API_KEY=ghu_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# 2. GOOGLE GEMINI (GRATIS con límites)
# Registro: https://makersuite.google.com/app/apikey  
# Límite: 60 requests/minuto
# GEMINI_API_KEY=AIzaSyXxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# 3. HUGGING FACE (GRATIS con rate limits)
# Registro: https://huggingface.co/settings/tokens
# HUGGINGFACE_API_KEY=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# 4. OLLAMA (Local - Sin API key necesaria)
# Instalación: https://ollama.ai
# No requiere API key, ejecuta modelos localmente
# LLM_PROVIDER=ollama

# =====================================
# CONFIGURACIÓN OPCIONAL
# =====================================

# Directorio para guardar evaluaciones
OUTPUT_DIRECTORY=./evaluaciones

# Timeout para evaluaciones (segundos)
EVALUATION_TIMEOUT=300

# Modelo específico a usar (varía por proveedor)
MODEL_NAME=gpt-4o-mini

# Configuración de logging
LOG_LEVEL=INFO
LOG_FILE=evaluaciones.log

# =====================================
# CONFIGURACIÓN AVANZADA
# =====================================

# Base URL personalizada para APIs
# OPENAI_BASE_URL=https://api.openai.com/v1
# GITHUB_MODELS_BASE_URL=https://models.inference.ai.azure.com

# Headers adicionales para requests
# CUSTOM_HEADERS={"User-Agent": "RubricaEvaluator/1.0"}

# Configuración de proxy (si es necesario)
# HTTP_PROXY=http://proxy.company.com:8080
# HTTPS_PROXY=https://proxy.company.com:8080

# =====================================
# CONFIGURACIÓN DE NOTIFICACIONES
# =====================================

# Email para notificaciones (opcional)
NOTIFICATION_EMAIL=tu_email@universidad.cl
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=tu_usuario@gmail.com
SMTP_PASSWORD=tu_password_app

# Webhook para Slack/Discord (opcional)
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/xxx/xxx/xxx
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/xxx/xxx

# =====================================
# CONFIGURACIÓN DE DESARROLLO
# =====================================

# Modo debug (muestra más información)
DEBUG=false

# Usar cache para evitar re-evaluaciones
USE_CACHE=true
CACHE_DIRECTORY=./.cache

# Número máximo de repositorios a procesar en paralelo
MAX_CONCURRENT_EVALUATIONS=3

# =====================================
# INSTRUCCIONES DE CONFIGURACIÓN
# =====================================

# 1. Copia este archivo: cp .env.example .env
# 2. Edita .env con tus valores reales
# 3. NUNCA subas el archivo .env a Git (ya está en .gitignore)

# PASOS PARA OBTENER TOKENS:

# GitHub Token:
# 1. Ve a https://github.com/settings/tokens
# 2. "Generate new token (classic)"
# 3. Nombre: "Rubrica Evaluator"
# 4. Selecciona scopes: repo, read:user, read:org
# 5. Copia el token a GITHUB_TOKEN

# GitHub Models API (Recomendado):
# 1. Ve a https://github.com/marketplace/models
# 2. Selecciona un modelo (ej: GPT-4o-mini)
# 3. "Get API Key"
# 4. Copia la key a LLM_API_KEY

# Google Gemini API:
# 1. Ve a https://makersuite.google.com/app/apikey
# 2. "Create API Key"
# 3. Copia la key a LLM_API_KEY

# Hugging Face Token:
# 1. Ve a https://huggingface.co/settings/tokens  
# 2. "New token"
# 3. Tipo: "Read"
# 4. Copia el token a LLM_API_KEY

# Ollama (Local):
# 1. Instala desde https://ollama.ai
# 2. Ejecuta: ollama pull llama2
# 3. No necesitas API key
# 4. Configura LLM_PROVIDER=ollama

# =====================================
# VERIFICACIÓN DE CONFIGURACIÓN
# =====================================

# Para verificar que todo está configurado:
# python -c "from src.config import Config; Config.validate_config()"

# Para probar conexión a GitHub:
# python -c "from github import Github; print(Github('$GITHUB_TOKEN').get_user().login)"

# Para probar el LLM:
# python simple_evaluator.py --repo https://github.com/octocat/Hello-World
