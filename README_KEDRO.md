# ğŸ“ Sistema de EvaluaciÃ³n AutomÃ¡tica para Proyectos Kedro ML

[![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)](https://www.python.org/)
[![Kedro](https://img.shields.io/badge/kedro-v0.18+-green.svg)](https://kedro.org/)
[![GitHub](https://img.shields.io/badge/github-api-orange.svg)](https://docs.github.com/en/rest)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

Sistema profesional para evaluar automÃ¡ticamente proyectos de Machine Learning implementados con el framework Kedro, siguiendo la metodologÃ­a CRISP-DM y utilizando agentes inteligentes con Ollama.

## ğŸ“‹ CaracterÃ­sticas Principales

### âœ… EvaluaciÃ³n AutomÃ¡tica Completa
- **10 criterios de evaluaciÃ³n** con ponderaciÃ³n del 10% cada uno
- **Escala de notas chilena** (1.0 - 7.0)
- **AnÃ¡lisis profundo** de estructura, cÃ³digo y documentaciÃ³n
- **EvaluaciÃ³n masiva** de mÃºltiples repositorios en paralelo

### ğŸ¤– Inteligencia Artificial Local
- **Ollama** para anÃ¡lisis con LLMs locales
- **Sin costos de API** - completamente local
- **Privacidad garantizada** - los datos no salen de tu servidor

### ğŸ“Š Reportes Detallados
- **Reportes individuales** en HTML, Markdown y JSON
- **EstadÃ­sticas del curso** con distribuciÃ³n de notas
- **ExportaciÃ³n** a Excel y CSV
- **Dashboard interactivo** (opcional)

## ğŸš€ InstalaciÃ³n RÃ¡pida

### OpciÃ³n 1: InstalaciÃ³n AutomÃ¡tica
```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/rubrica-evaluator.git
cd rubrica-evaluator

# ConfiguraciÃ³n rÃ¡pida completa
make quick-start
```

### OpciÃ³n 2: InstalaciÃ³n Manual
```bash
# 1. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Configurar GitHub token
export GITHUB_TOKEN="ghp_tuTokenAqui"

# 4. Instalar Ollama (opcional pero recomendado)
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull llama2
```

## ğŸ“ Estructura del Proyecto

```
rubrica-evaluator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ kedro_evaluator.py      # Evaluador principal para Kedro
â”‚   â””â”€â”€ rubrica_evaluator.py    # Sistema base de evaluaciÃ³n
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ rubrica_kedro.py         # RÃºbrica especÃ­fica para proyectos Kedro
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ evaluate_batch.py        # EvaluaciÃ³n masiva
â”‚   â””â”€â”€ validate_installation.py # Validador de instalaciÃ³n
â”œâ”€â”€ data/
â”‚   â””â”€â”€ estudiantes_kedro.csv   # Lista de estudiantes
â”œâ”€â”€ evaluaciones/                # Resultados de evaluaciones (generado)
â”œâ”€â”€ requirements.txt             # Dependencias Python
â”œâ”€â”€ Makefile                     # Comandos simplificados
â””â”€â”€ README.md                    # Este archivo
```

## ğŸ’» Uso del Sistema

### EvaluaciÃ³n Individual
```bash
# Con Make
make evaluate-single REPO=https://github.com/estudiante/proyecto STUDENT="Juan PÃ©rez"

# O directamente con Python
python src/kedro_evaluator.py $GITHUB_TOKEN https://github.com/estudiante/proyecto "Juan PÃ©rez"
```

### EvaluaciÃ³n Masiva (Recomendado)
```bash
# Evaluar todos los estudiantes del CSV
make evaluate-all

# O con parÃ¡metros personalizados
python scripts/evaluate_batch.py \
    --csv data/estudiantes_kedro.csv \
    --output evaluaciones \
    --parallel 3
```

### Generar Reportes
```bash
# Generar reportes consolidados
make report

# Ver estadÃ­sticas rÃ¡pidas
make stats
```

## ğŸ“ Formato del CSV de Estudiantes

El archivo `data/estudiantes_kedro.csv` debe tener el siguiente formato:

```csv
nombre,pareja,repositorio
Juan PÃ©rez,MarÃ­a GonzÃ¡lez,https://github.com/juanperez/kedro-ml-project
Ana RodrÃ­guez,Carlos LÃ³pez,https://github.com/anarodriguez/proyecto-kedro
Pedro MartÃ­nez,,https://github.com/pmartinez/ml-kedro-parcial1
```

## ğŸ“Š Criterios de EvaluaciÃ³n

El sistema evalÃºa los siguientes 10 criterios, cada uno con 10% de ponderaciÃ³n:

1. **Estructura y ConfiguraciÃ³n del Proyecto Kedro**
2. **ImplementaciÃ³n del CatÃ¡logo de Datos** (mÃ­nimo 3 datasets)
3. **Desarrollo de Nodos y Funciones**
4. **ConstrucciÃ³n de Pipelines**
5. **AnÃ¡lisis Exploratorio de Datos (EDA)**
6. **Limpieza y Tratamiento de Datos**
7. **TransformaciÃ³n y Feature Engineering**
8. **IdentificaciÃ³n de Targets para ML**
9. **DocumentaciÃ³n y Notebooks**
10. **Reproducibilidad y Mejores PrÃ¡cticas**

### Bonificaciones (Puntos Extra)
- **Kedro Viz**: +0.3
- **Tests Unitarios**: +0.5
- **CI/CD**: +0.3
- **Docker**: +0.2
- **Dashboard**: +0.5

### Penalizaciones
- **Entrega tardÃ­a**: -0.5 por dÃ­a
- **Falta de dataset**: -1.0 por cada uno bajo 3
- **Proyecto no ejecuta**: -2.0

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno
```bash
# Obligatorias
export GITHUB_TOKEN="ghp_tuTokenAqui"

# Opcionales
export LLM_PROVIDER="ollama"  # o "github", "gemini"
export OUTPUT_DIRECTORY="./evaluaciones"
export EVALUATION_TIMEOUT=300
```

### Personalizar la RÃºbrica
Edita `examples/rubrica_kedro.py` para ajustar:
- Ponderaciones de criterios
- Niveles de evaluaciÃ³n
- Archivos a revisar
- Bonificaciones y penalizaciones

## ğŸ³ Uso con Docker

```bash
# Construir imagen
docker build -t kedro-evaluator .

# Ejecutar evaluaciÃ³n
docker run -it --rm \
    -v $(pwd)/data:/app/data \
    -v $(pwd)/evaluaciones:/app/evaluaciones \
    -e GITHUB_TOKEN=$GITHUB_TOKEN \
    kedro-evaluator
```

## ğŸ§ª Testing y ValidaciÃ³n

```bash
# Validar instalaciÃ³n
make validate

# Ejecutar tests
make test

# Tests con cobertura
make dev-test-coverage
```

## ğŸ“ˆ Ejemplos de Output

### EvaluaciÃ³n Individual
```
âœ… Juan PÃ©rez: Nota 5.8 - APROBADO
   - Estructura: 80%
   - CatÃ¡logo: 100%
   - Pipelines: 60%
   - DocumentaciÃ³n: 80%
   ...
```

### EstadÃ­sticas del Curso
```
Total evaluados: 25
Aprobados: 18 (72%)
Nota promedio: 5.2
Nota mÃ¡xima: 6.8
Nota mÃ­nima: 3.2
```

## ğŸ› ï¸ Comandos Ãštiles (Makefile)

| Comando | DescripciÃ³n |
|---------|-------------|
| `make help` | Muestra todos los comandos disponibles |
| `make setup` | ConfiguraciÃ³n inicial completa |
| `make evaluate-all` | EvalÃºa todos los estudiantes |
| `make stats` | Muestra estadÃ­sticas rÃ¡pidas |
| `make clean` | Limpia archivos temporales |
| `make backup` | Crea backup de evaluaciones |

## ğŸ› SoluciÃ³n de Problemas

### Ollama no responde
```bash
# Verificar que el servicio estÃ© activo
ollama serve

# Verificar modelos disponibles
ollama list
```

### GitHub API Rate Limit
- Usar token con mÃ¡s permisos
- Implementar cache: `--use-cache`
- Reducir paralelismo

### Proyecto no se puede clonar
- Verificar que el repositorio sea pÃºblico
- Comprobar URL correcta
- Revisar permisos del token

## ğŸ“š DocumentaciÃ³n de la Asignatura

- **Curso**: MLY0100 - Machine Learning
- **EvaluaciÃ³n**: Parcial 1 (40% de la asignatura)
- **Componentes**:
  - Prueba TeÃ³rica: 30%
  - Proyecto PrÃ¡ctico con Kedro: 70% (evaluado por este sistema)
- **Modalidad**: Parejas
- **DuraciÃ³n**: 4 semanas
- **MetodologÃ­a**: CRISP-DM (3 primeras fases)

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¨â€ğŸ« CrÃ©ditos

Desarrollado para el curso de Machine Learning (MLY0100) para facilitar la evaluaciÃ³n justa, consistente y eficiente de proyectos estudiantiles.

## ğŸ“ Soporte

Para soporte y consultas:
- ğŸ“§ Email: giocrisrai.godoy@profesor.duoc.cl
- ğŸ’¬ Issues: [GitHub Issues](https://github.com/tu-usuario/rubrica-evaluator/issues)

---

*Sistema de EvaluaciÃ³n AutomÃ¡tica v1.0 - Facilitando la evaluaciÃ³n de proyectos de Machine Learning*
