#!/usr/bin/env python3
"""
Agente de AnÃ¡lisis Inteligente para Evaluaciones
Basado en la configuraciÃ³n de GitHub Models del proyecto de curso
"""

import os
import json
import sys
from typing import List, Dict, Any
from dataclasses import dataclass
from datetime import datetime
import openai
import requests
from dotenv import load_dotenv

# Agregar src al path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from config import Config

# Cargar variables de entorno
load_dotenv()

@dataclass
class EvaluationInsight:
    """Insight generado por el agente de anÃ¡lisis."""
    tipo: str  # "tendencia", "problema_comun", "recomendacion"
    titulo: str
    descripcion: str
    criterios_afectados: List[str]
    gravedad: str  # "baja", "media", "alta"
    evidencias: List[str]

class AnalysisAgent:
    """Agente inteligente para anÃ¡lisis de evaluaciones."""
    
    def __init__(self):
        """Inicializa el agente con configuraciÃ³n centralizada."""
        self.provider = Config.LLM_PROVIDER
        
        # Inicializar atributos por defecto
        self.client = None
        self.ollama_url = None
        
        if self.provider == "github":
            self.client = openai.OpenAI(
                base_url=Config.LLM_PROVIDERS["github"]["base_url"],
                api_key=Config.GITHUB_TOKEN
            )
            self.model = "gpt-4o-mini"
        elif self.provider == "ollama":
            self.ollama_url = Config.LLM_PROVIDERS["ollama"]["base_url"]
            self.model = "llama3:latest"
        else:
            # Fallback a GitHub Models
            self.client = openai.OpenAI(
                base_url=Config.LLM_PROVIDERS["github"]["base_url"],
                api_key=Config.GITHUB_TOKEN
            )
            self.model = "gpt-4o-mini"
        
    def analyze_evaluation_trends(self, evaluations: List[Dict]) -> List[EvaluationInsight]:
        """Analiza tendencias en mÃºltiples evaluaciones."""
        
        prompt = self._build_trend_analysis_prompt(evaluations)
        
        try:
            if self.provider == "github":
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system", 
                            "content": "Eres un experto analista educativo especializado en identificar patrones y tendencias en evaluaciones de proyectos de Machine Learning. Tu trabajo es encontrar insights valiosos que ayuden a mejorar la enseÃ±anza."
                        },
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3
                )
                insights_text = response.choices[0].message.content
                
            elif self.provider == "ollama":
                # Ollama API call
                ollama_payload = {
                    "model": self.model,
                    "prompt": f"Eres un experto analista educativo especializado en identificar patrones y tendencias en evaluaciones de proyectos de Machine Learning. SIEMPRE responde en ESPAÃ‘OL. Tu trabajo es encontrar insights valiosos que ayuden a mejorar la enseÃ±anza.\n\n{prompt}",
                    "stream": False,
                    "options": {
                        "temperature": 0.3,
                        "num_predict": 4000
                    }
                }
                
                response = requests.post(
                    f"{self.ollama_url}/api/generate",
                    json=ollama_payload,
                    timeout=120
                )
                
                if response.status_code == 200:
                    insights_text = response.json()["response"]
                else:
                    raise Exception(f"Error de Ollama: {response.status_code} - {response.text}")
            
            return self._parse_insights(insights_text)
            
        except Exception as e:
            print(f"Error en anÃ¡lisis de tendencias: {e}")
            return []
    
    def identify_common_issues(self, evaluations: List[Dict]) -> List[EvaluationInsight]:
        """Identifica problemas comunes en las evaluaciones."""
        
        prompt = self._build_issues_analysis_prompt(evaluations)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "Eres un mentor experto que identifica problemas recurrentes en proyectos de estudiantes. Ayudas a los profesores a entender quÃ© aspectos necesitan mÃ¡s atenciÃ³n pedagÃ³gica."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2
            )
            
            issues_text = response.choices[0].message.content
            return self._parse_insights(issues_text)
            
        except Exception as e:
            print(f"Error identificando problemas comunes: {e}")
            return []
    
    def generate_improvement_recommendations(self, evaluation: Dict) -> List[EvaluationInsight]:
        """Genera recomendaciones especÃ­ficas para una evaluaciÃ³n."""
        
        prompt = self._build_recommendation_prompt(evaluation)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "Eres un coach personalizado que da recomendaciones especÃ­ficas y accionables para mejorar proyectos de Machine Learning. Tus sugerencias son prÃ¡cticas y detalladas."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.4
            )
            
            recommendations_text = response.choices[0].message.content
            return self._parse_insights(recommendations_text)
            
        except Exception as e:
            print(f"Error generando recomendaciones: {e}")
            return []
    
    def _build_trend_analysis_prompt(self, evaluations: List[Dict]) -> str:
        """Construye prompt para anÃ¡lisis de tendencias."""
        
        # Preparar datos para anÃ¡lisis
        criterios_stats = {}
        notas_totales = []
        
        for eval_data in evaluations:
            notas_totales.append(eval_data.get('nota_final', 0))
            
            for criterio in eval_data.get('criterios', []):
                nombre = criterio.get('criterio', '')
                puntuacion = criterio.get('puntuacion', 0)
                
                if nombre not in criterios_stats:
                    criterios_stats[nombre] = []
                criterios_stats[nombre].append(puntuacion)
        
        # Calcular estadÃ­sticas
        stats_text = f"""
DATOS DE ANÃLISIS:
- Total evaluaciones: {len(evaluations)}
- Nota promedio: {sum(notas_totales)/len(notas_totales):.2f}/7.0
- Nota mÃ¡xima: {max(notas_totales):.2f}/7.0
- Nota mÃ­nima: {min(notas_totales):.2f}/7.0

ESTADÃSTICAS POR CRITERIO:
"""
        
        for criterio, puntuaciones in criterios_stats.items():
            promedio = sum(puntuaciones) / len(puntuaciones)
            stats_text += f"- {criterio}: {promedio:.1f}% promedio\n"
        
        prompt = f"""
Analiza las siguientes tendencias en las evaluaciones de proyectos de Machine Learning:

{stats_text}

EVALUACIONES DETALLADAS:
{json.dumps(evaluations, indent=2, ensure_ascii=False)}

INSTRUCCIONES:
1. Identifica 3-5 tendencias principales
2. Encuentra patrones en criterios con bajo rendimiento
3. Analiza correlaciones entre diferentes aspectos
4. Sugiere Ã¡reas de mejora pedagÃ³gica

FORMATO DE RESPUESTA (JSON):
[
    {{
        "tipo": "tendencia",
        "titulo": "TÃ­tulo de la tendencia",
        "descripcion": "DescripciÃ³n detallada...",
        "criterios_afectados": ["criterio1", "criterio2"],
        "gravedad": "media",
        "evidencias": ["evidencia1", "evidencia2"]
    }}
]
"""
        return prompt
    
    def _build_issues_analysis_prompt(self, evaluations: List[Dict]) -> str:
        """Construye prompt para anÃ¡lisis de problemas comunes."""
        
        prompt = f"""
Analiza los problemas mÃ¡s comunes en estas evaluaciones de proyectos de Machine Learning:

{json.dumps(evaluations, indent=2, ensure_ascii=False)}

INSTRUCCIONES:
1. Identifica los 5 problemas mÃ¡s recurrentes
2. Clasifica por gravedad (alta/media/baja)
3. Sugiere soluciones especÃ­ficas
4. EnfÃ³cate en aspectos pedagÃ³gicos

FORMATO DE RESPUESTA (JSON):
[
    {{
        "tipo": "problema_comun",
        "titulo": "Problema identificado",
        "descripcion": "DescripciÃ³n del problema...",
        "criterios_afectados": ["criterio1"],
        "gravedad": "alta",
        "evidencias": ["% de estudiantes afectados", "ejemplos especÃ­ficos"]
    }}
]
"""
        return prompt
    
    def _build_recommendation_prompt(self, evaluation: Dict) -> str:
        """Construye prompt para recomendaciones especÃ­ficas."""
        
        prompt = f"""
Genera recomendaciones especÃ­ficas para mejorar este proyecto de Machine Learning:

{json.dumps(evaluation, indent=2, ensure_ascii=False)}

INSTRUCCIONES:
1. EnfÃ³cate en los criterios con menor puntuaciÃ³n
2. Da recomendaciones accionables y especÃ­ficas
3. Prioriza las mejoras por impacto
4. Incluye recursos de aprendizaje

FORMATO DE RESPUESTA (JSON):
[
    {{
        "tipo": "recomendacion",
        "titulo": "RecomendaciÃ³n especÃ­fica",
        "descripcion": "DescripciÃ³n detallada...",
        "criterios_afectados": ["criterio1"],
        "gravedad": "alta",
        "evidencias": ["puntuaciÃ³n actual", "Ã¡rea de mejora"]
    }}
]
"""
        return prompt
    
    def _parse_insights(self, insights_text: str) -> List[EvaluationInsight]:
        """Parsea la respuesta del LLM en objetos EvaluationInsight."""
        try:
            # Buscar JSON en la respuesta
            start = insights_text.find('[')
            end = insights_text.rfind(']') + 1
            json_str = insights_text[start:end]
            
            insights_data = json.loads(json_str)
            insights = []
            
            for insight_data in insights_data:
                insight = EvaluationInsight(
                    tipo=insight_data.get('tipo', ''),
                    titulo=insight_data.get('titulo', ''),
                    descripcion=insight_data.get('descripcion', ''),
                    criterios_afectados=insight_data.get('criterios_afectados', []),
                    gravedad=insight_data.get('gravedad', 'media'),
                    evidencias=insight_data.get('evidencias', [])
                )
                insights.append(insight)
            
            return insights
            
        except Exception as e:
            print(f"Error parseando insights: {e}")
            return []
    
    def generate_summary_report(self, insights: List[EvaluationInsight]) -> str:
        """Genera un reporte resumen de los insights."""
        
        if not insights:
            return "No se generaron insights en el anÃ¡lisis."
        
        report = f"# ğŸ“Š Reporte de AnÃ¡lisis Inteligente\n\n"
        report += f"**Fecha:** {datetime.now().strftime('%d/%m/%Y %H:%M')}\n"
        report += f"**Total Insights:** {len(insights)}\n\n"
        
        # Agrupar por tipo
        by_type = {}
        for insight in insights:
            if insight.tipo not in by_type:
                by_type[insight.tipo] = []
            by_type[insight.tipo].append(insight)
        
        for tipo, insights_list in by_type.items():
            tipo_title = {
                'tendencia': 'ğŸ” Tendencias Identificadas',
                'problema_comun': 'âš ï¸ Problemas Comunes',
                'recomendacion': 'ğŸ’¡ Recomendaciones'
            }.get(tipo, f'ğŸ“‹ {tipo.title()}')
            
            report += f"## {tipo_title}\n\n"
            
            for insight in insights_list:
                gravedad_emoji = {
                    'alta': 'ğŸ”´',
                    'media': 'ğŸŸ¡',
                    'baja': 'ğŸŸ¢'
                }.get(insight.gravedad, 'âšª')
                
                report += f"### {gravedad_emoji} {insight.titulo}\n\n"
                report += f"{insight.descripcion}\n\n"
                
                if insight.criterios_afectados:
                    report += f"**Criterios afectados:** {', '.join(insight.criterios_afectados)}\n\n"
                
                if insight.evidencias:
                    report += f"**Evidencias:**\n"
                    for evidencia in insight.evidencias:
                        report += f"- {evidencia}\n"
                    report += "\n"
                
                report += "---\n\n"
        
        return report


# Ejemplo de uso
if __name__ == "__main__":
    # Crear agente
    agent = AnalysisAgent()
    
    # Datos de ejemplo (en la prÃ¡ctica vendrÃ­an de evaluaciones reales)
    sample_evaluations = [
        {
            "repositorio": "https://github.com/estudiante1/proyecto-ml",
            "nota_final": 5.2,
            "criterios": [
                {"criterio": "Estructura del Proyecto", "puntuacion": 60},
                {"criterio": "AnÃ¡lisis de Datos", "puntuacion": 80},
                {"criterio": "Modelado", "puntuacion": 40}
            ]
        },
        {
            "repositorio": "https://github.com/estudiante2/proyecto-ml",
            "nota_final": 4.8,
            "criterios": [
                {"criterio": "Estructura del Proyecto", "puntuacion": 70},
                {"criterio": "AnÃ¡lisis de Datos", "puntuacion": 50},
                {"criterio": "Modelado", "puntuacion": 45}
            ]
        }
    ]
    
    print("ğŸ¤– Agente de AnÃ¡lisis Inteligente")
    print("=" * 50)
    
    # AnÃ¡lisis de tendencias
    print("ğŸ“ˆ Analizando tendencias...")
    trends = agent.analyze_evaluation_trends(sample_evaluations)
    print(f"âœ… Encontradas {len(trends)} tendencias")
    
    # Problemas comunes
    print("\nâš ï¸ Identificando problemas comunes...")
    issues = agent.identify_common_issues(sample_evaluations)
    print(f"âœ… Identificados {len(issues)} problemas")
    
    # Generar reporte
    all_insights = trends + issues
    report = agent.generate_summary_report(all_insights)
    
    print("\nğŸ“Š Reporte generado:")
    print(report)
